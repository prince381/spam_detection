{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPAM DETECTION MODEL\n",
    "\n",
    "#### Project completed by: Prince Owusu\n",
    "[Email](powusu381@gmail.com) || [linkedIn](https://www.linkedin.com/in/prince-owusu-356914198?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_contact_details%3B2NYoXqMHQKOMp0yWSME5mQ%3D%3D) || [Twitter](https://twitter.com/iam_kwekhu)\n",
    "\n",
    "In this jupyter notebook, I will demonstrate a real world example of text classification using\n",
    "machine learning. The goal of this project is to train a text classification machine learning model\n",
    "in python capable of predicting whether a text message is spam or not. I will use pythonâ€™s Scikit\n",
    "learn library for machine learning to train the text classification model.\n",
    "\n",
    "This jupyter notebook highlights the following:\n",
    "* Importing the libraries needed\n",
    "* Importing the data set\n",
    "* Text preprocessing\n",
    "* Converting text to numbers\n",
    "* Splitting the data into train and test sets\n",
    "* Training the text classification model and predicting SMS messages as spam or ham\n",
    "* Evaluating the  model\n",
    "* Saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the neccessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from stopwords import final_stopwords\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RandomizedSearchCV,cross_val_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from IPython.display import display\n",
    "from textblob import TextBlob,Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data file with pandas read_csv\n",
    "file = '.\\\\Desktop\\\\EDUCATE\\\\DATA CSV\\\\Spam detection project\\\\data\\\\sms_messages.csv'\n",
    "data = pd.read_csv(file)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "Once the data has been imported, the next step is to preprocess the text. Text may contain numbers, special characters, and unwanted spaces. We will remove all the special characters, numbers, and unwanted spaces from our text. The final preprocessing step will be the lemmatization. In lemmatization, we reduce the word into dictionary root form. For instance 'cats' is converted into 'cat'. Lemmatization is done in order to avoid creating features that are semantically similar but syntactically different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of text messages: 5572\n",
      "\n",
      "Number of duplicated messages: 403\n",
      "\n",
      "Number of missing values in each column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "sms      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of text messages\n",
    "print('Total number of text messages: {}\\n'.format(data.shape[0]))\n",
    "\n",
    "# check the number of duplicated messages\n",
    "print('Number of duplicated messages: {}\\n'.format(data.duplicated().sum()))\n",
    "\n",
    "# check for missing values in the data\n",
    "print('Number of missing values in each column:')\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                sms\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop all the duplicated text messages from the data\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# remove all extra spaces from the text by trimming the whitespaces off the text\n",
    "data.sms = data.sms.str.strip()\n",
    "data.label = data.label.str.strip()\n",
    "\n",
    "# reset index and drop an unwanted 'index' column that will be created\n",
    "data = data.reset_index()\n",
    "data = data.drop('index',axis=1)\n",
    "\n",
    "# encode the target variables\n",
    "data.label = data.label.map({'spam':1,'ham':0})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go jurong point crazy Available in bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry 2 wkly comp win FA Cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun so early hor U c then</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I n't to usf he lives here</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                sms\n",
       "0      0  Go jurong point crazy Available in bugis n gre...\n",
       "1      0                            Ok lar Joking wif u oni\n",
       "2      1  Free entry 2 wkly comp win FA Cup final tkts 2...\n",
       "3      0                        U dun so early hor U c then\n",
       "4      0                     Nah I n't to usf he lives here"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove all stopwords and punctuation marks\n",
    "stp_wrds = final_stopwords\n",
    "\n",
    "# loop through all the text messages in the data and remove all stopwords\n",
    "for i in range(len(data)):\n",
    "    # get the text\n",
    "    text = data.sms[i]\n",
    "    # create a textblob object\n",
    "    blob = TextBlob(text)\n",
    "    # convert the text into a list of words\n",
    "    words = blob.words\n",
    "    # loop through all the words and identify the stopwords and remove them\n",
    "    for word in words:\n",
    "        wrd = word.strip()\n",
    "        if wrd in stp_wrds:\n",
    "            words.remove(word)\n",
    "        else:\n",
    "            continue\n",
    "    line = ' '.join(words)\n",
    "    data.sms[i] = line\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go jurong point crazy Available in bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry wkly comp win FA Cup final tkts 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun so early hor U c then</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I n't to usf he lives here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey darling 's week 's and word back I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Even brother not to speak They treat me like a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>As request 'Melle Melle Oru Minnaminunginte Nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER As valued network customer have selecte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Had mobile 11 months more U R entitled Update ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                sms\n",
       "0      0  Go jurong point crazy Available in bugis n gre...\n",
       "1      0                            Ok lar Joking wif u oni\n",
       "2      1  Free entry wkly comp win FA Cup final tkts 21s...\n",
       "3      0                        U dun so early hor U c then\n",
       "4      0                     Nah I n't to usf he lives here\n",
       "5      1  FreeMsg Hey darling 's week 's and word back I...\n",
       "6      0  Even brother not to speak They treat me like a...\n",
       "7      0  As request 'Melle Melle Oru Minnaminunginte Nu...\n",
       "8      1  WINNER As valued network customer have selecte...\n",
       "9      1  Had mobile 11 months more U R entitled Update ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "# remove all the numbers from the text\n",
    "for i in range(len(data)):\n",
    "    # get the text message\n",
    "    txt_msg = data.sms[i]\n",
    "    # split the text into a list of single characters\n",
    "    char_list = txt_msg.split()\n",
    "    # loop through the list and get rid of the numbers\n",
    "    for j in char_list:\n",
    "        if j in numbers:\n",
    "            char_list.remove(j)\n",
    "        else:\n",
    "            continue\n",
    "    new_text = ' '.join(char_list)\n",
    "    data.sms[i] = new_text\n",
    "    \n",
    "# print the first ten rows of the data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go jurong point crazy Available in bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry wkly comp win FA Cup final tkts 21s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun so early hor U c then</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I n't to usf he life here</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                sms\n",
       "0      0  Go jurong point crazy Available in bugis n gre...\n",
       "1      0                            Ok lar Joking wif u oni\n",
       "2      1  Free entry wkly comp win FA Cup final tkts 21s...\n",
       "3      0                        U dun so early hor U c then\n",
       "4      0                      Nah I n't to usf he life here"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we now lemmatize all the words\n",
    "for i in range(len(data)):\n",
    "    # get the text message\n",
    "    txt = data.sms[i]\n",
    "    # create a textblob object\n",
    "    blb = TextBlob(txt)\n",
    "    # convert the text into a list of words\n",
    "    wrds = blb.words\n",
    "    wrd_container = []\n",
    "    # iterate over the words and lemmatize each one of them\n",
    "    for wrd in wrds:\n",
    "        new_wrd = Word(wrd)\n",
    "        lem_word = new_wrd.lemmatize()\n",
    "        wrd_container.append(lem_word)\n",
    "    # join the lemmatized words\n",
    "    wrd_line = ' '.join(wrd_container)\n",
    "    data.sms[i] = wrd_line\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Text to Numbers\n",
    "Machine unlike humans, cannot understand the raw text. Machines can only see numbers. Particularly, statistical techniques such as machine learning can only deal with numbers. Therefore we need to convert our text into numbers. To do this task, we will use the TfidfVectorizer to convert the text to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training X: (3875, 7007)\n",
      "\n",
      "Shape of training y: (3875,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "\n",
    "X = data.sms\n",
    "y = data.label\n",
    "\n",
    "# split the data into train and test set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.25)\n",
    "\n",
    "# convert the text into numbers\n",
    "vec = TfidfVectorizer()\n",
    "training_x = vec.fit_transform(X_train)\n",
    "testing_x = vec.transform(X_test)\n",
    "\n",
    "# check the shape of the training X and the training y\n",
    "print('Shape of training X: {}\\n'.format(training_x.shape))\n",
    "print('Shape of training y: {}\\n'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting, Evaluation, and Hyper-parameter tunning\n",
    "This is the point where we train our text classification model, make predictions, and evaluate it. The model I will train is the Multinomial Naive Bayes (MultinomialNB) and evaluate it by calculating the accuracy score, precision score, and the recall score. After scoring the model, we will try to improve the model performance by tunning its hyper-parameters and obtain a higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the model: 0.9628482972136223\n",
      "\n",
      "Precision score of the model: 0.9911504424778761\n",
      "\n",
      "Recall score of the model: 0.7044025157232704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the model instance\n",
    "naive_model = MultinomialNB()\n",
    "\n",
    "# fit the model on the training data\n",
    "naive_model.fit(training_x,y_train)\n",
    "\n",
    "# make predictions \n",
    "predictions = naive_model.predict(testing_x)\n",
    "\n",
    "# score the model\n",
    "print('Accuracy score of the model: {}\\n'.format(accuracy_score(y_test,predictions)))\n",
    "# display the classification report\n",
    "print('Precision score of the model: {}\\n'.format(precision_score(y_test,predictions)))\n",
    "print('Recall score of the model: {}\\n'.format(recall_score(y_test,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                     fit_prior=True),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'alpha': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
       "       1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. ]),\n",
       "                         'fit_prior': [True, False]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tunning hyper-parameters\n",
    "params = {'alpha':np.linspace(0.1,2,20),\n",
    "         'fit_prior':[True,False]}\n",
    "\n",
    "# instantiate the model\n",
    "bayes_model = MultinomialNB()\n",
    "\n",
    "# define the grid search parameters\n",
    "grid_search = GridSearchCV(estimator=bayes_model,\n",
    "                          param_grid=params,\n",
    "                          cv=5,\n",
    "                          n_jobs=-1,\n",
    "                          verbose=2)\n",
    "\n",
    "# fit the model to start the grid search\n",
    "grid_search.fit(training_x,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the model: 0.9852941176470589\n",
      "\n",
      "Precision score of the model: 0.9794520547945206\n",
      "\n",
      "Recall score of the model: 0.89937106918239\n",
      "\n",
      "Best parameters found by the grid search:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.2, 'fit_prior': True}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions \n",
    "grid_predictions = grid_search.predict(testing_x)\n",
    "\n",
    "# score the model\n",
    "print('Accuracy score of the model: {}\\n'.format(accuracy_score(y_test,grid_predictions)))\n",
    "# display the classification report\n",
    "print('Precision score of the model: {}\\n'.format(precision_score(y_test,grid_predictions)))\n",
    "print('Recall score of the model: {}\\n'.format(recall_score(y_test,grid_predictions)))\n",
    "# print out the best parameters found by the grid search for fitting the model on the data\n",
    "print('Best parameters found by the grid search:')\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the hyper-parameter tunning really helped improved the performance of the model. The accuracy of the model has now increased from 0.963 to 0.985 which is better and more accurate for prediction. The precision score tells us the accuracy of the positive predictions and the recall score, also called sensitivity or true positive rate (TPR) also tells us the ratio of positive instances that are correctly detected by the classifier. Having this, we now make a pipeline for our data fitting using the best parameters found in the grid search.ie. {'alpha': 0.2, 'fit_prior': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the model: 0.9852941176470589\n",
      "\n",
      "Precision score of the model: 0.9794520547945206\n",
      "\n",
      "Recall score of the model: 0.89937106918239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make a pipeline and fit the model on the X_train and y_train\n",
    "final_model = make_pipeline(TfidfVectorizer(),MultinomialNB(alpha=0.2,fit_prior=True))\n",
    "\n",
    "# fit the model on the training data\n",
    "final_model.fit(X_train,y_train)\n",
    "\n",
    "# make predictions \n",
    "final_predictions = final_model.predict(X_test)\n",
    "\n",
    "# score the model\n",
    "print('Accuracy score of the model: {}\\n'.format(accuracy_score(y_test,final_predictions)))\n",
    "# display the classification report\n",
    "print('Precision score of the model: {}\\n'.format(precision_score(y_test,final_predictions)))\n",
    "print('Recall score of the model: {}\\n'.format(recall_score(y_test,final_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the final model on our computer's hard disk.\n",
    "The text classification model to detect whether an SMS is spam or not (ham) has been successfully trained and ready to be deployed and used in applications. The next thing to do is save the model into a pickle file ('.pkl' file) on our computer's hard disk so that we can load it whenever we are ready to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library that allows us to save and load our model.\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\Desktop\\\\EDUCATE\\\\DATA CSV\\\\Spam detection project\\\\spam_detection_model.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my file directory on my computer\n",
    "file_dir = '.\\\\Desktop\\\\EDUCATE\\\\DATA CSV\\\\Spam detection project\\\\spam_detection_model.pkl'\n",
    "# save the model\n",
    "joblib.dump(final_model,file_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has now been saved and can be loaded again using the syntax:\n",
    "\n",
    "In [1]: classifier = joblib.load(file_name)\n",
    "\n",
    "This brings me to the end of my machine learning project and I have successfully trained a text classification model (Multinomial Naive Bayes Classification model) which can be used in applications to detect a spam message. Please do not hesitate to contact me for any sort of collaboration of discussion about this notebook. Thank you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project  completed by: Prince Owusu\n",
    "[Email](powusu381@gmail.com) || [linkedIn](https://www.linkedin.com/in/prince-owusu-356914198?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_contact_details%3B2NYoXqMHQKOMp0yWSME5mQ%3D%3D) || [Twitter](https://twitter.com/iam_kwekhu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
